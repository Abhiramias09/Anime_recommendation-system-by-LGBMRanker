{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPxptg6N810FDSH2pQBFBSr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhiramias09/Anime_recommendation-system-by-LGBMRanker/blob/main/miniproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from lightgbm import LGBMRanker\n",
        "import pickle\n",
        "\n",
        "# Unzip the dataset\n",
        "zipped_data = zipfile.ZipFile(\"/content/anime-recommendation-ltr-dataset.zip\")\n",
        "\n",
        "# Load the datasets\n",
        "anime_info_df = pd.read_csv(zipped_data.open('anime_info.csv'))\n",
        "relavence_scores = pd.read_csv(zipped_data.open('relavence_scores.csv'))\n",
        "user_info = pd.read_csv(zipped_data.open('user_info.csv'))\n",
        "\n",
        "# Define popular genres\n",
        "popular_genres = ['Comedy', 'Action', 'Fantasy', 'Adventure', 'Kids', 'Drama', 'Sci-Fi', 'Music', 'Shounen', 'Slice of Life']\n",
        "\n",
        "# Function to create genre flags\n",
        "def create_genre_flags(df, popular_genres):\n",
        "    df = df.dropna(subset=['Genres'])\n",
        "    df['Genres'] = df['Genres'].apply(lambda x: \",\".join(s.strip() for s in x.split(\",\")))\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    genre_df = pd.DataFrame(mlb.fit_transform(df['Genres'].str.split(',')),\n",
        "                            columns=mlb.classes_,\n",
        "                            index=df.index)\n",
        "    new_df = pd.concat([df['anime_id'], genre_df[popular_genres]], axis=1)\n",
        "    new_df.columns = ['anime_id'] + popular_genres\n",
        "    return new_df\n",
        "\n",
        "# Create genre flags and merge with anime info\n",
        "anime_genre_info_df = create_genre_flags(anime_info_df, popular_genres)\n",
        "anime_info_df_final = anime_info_df.merge(anime_genre_info_df, on='anime_id')\n",
        "anime_info_df_final.columns = [col if col == 'anime_id' else f\"ANIME_FEATURE {col}\".upper() for col in anime_info_df_final.columns]\n",
        "\n",
        "# Rename user info columns\n",
        "user_info.columns = [col if col == 'user_id' else f\"USER_FEATURE {col}\".upper() for col in user_info.columns]\n",
        "\n",
        "# Merge dataframes\n",
        "train_interim = relavence_scores.merge(anime_info_df_final)\n",
        "train = train_interim.merge(user_info, how='inner')\n",
        "\n",
        "# Drop columns with more than 50% missing values\n",
        "na_counts = (train.isna().sum() * 100 / len(train))\n",
        "train_processed = train.drop(na_counts[na_counts > 50].index, axis=1)\n",
        "\n",
        "# Sort by user_id\n",
        "train_processed.sort_values(by='user_id', inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "features = ['anime_id', 'user_id', 'ANIME_FEATURE IS_TV',\n",
        "       'ANIME_FEATURE YEAR_AIRED', 'ANIME_FEATURE IS_ADULT',\n",
        "\n",
        "       'ANIME_FEATURE ABOVE_FIVE_STAR_RATINGS',\n",
        "       'ANIME_FEATURE ABOVE_FIVE_STAR_RATIO', 'ANIME_FEATURE COMEDY',\n",
        "       'ANIME_FEATURE ACTION', 'ANIME_FEATURE FANTASY',\n",
        "       'ANIME_FEATURE ADVENTURE','ANIME_FEATURE DRAMA',\n",
        "       'ANIME_FEATURE SCI-FI', 'ANIME_FEATURE MUSIC', 'ANIME_FEATURE SHOUNEN',\n",
        "       'ANIME_FEATURE SLICE OF LIFE', 'USER_FEATURE REVIEW_COUNT',\n",
        "       'USER_FEATURE AVG_SCORE', 'USER_FEATURE SCORE_STDDEV',\n",
        "       'USER_FEATURE ABOVE_FIVE_STAR_COUNT',\n",
        "       'USER_FEATURE ABOVE_FIVE_STAR_RATIO']\n",
        "target = 'relavence_score'\n",
        "\n",
        "# Function to limit the number of entries per user to 10,000\n",
        "def limit_entries_per_user(df, limit=10000):\n",
        "    limited_df = df.groupby('user_id').apply(lambda x: x.head(limit)).reset_index(drop=True)\n",
        "    return limited_df\n",
        "\n",
        "# Apply the limit to the training data\n",
        "train_processed_limited = limit_entries_per_user(train_processed)\n",
        "\n",
        "# Split data into training and test sets\n",
        "test_size = int(1e5)\n",
        "X, y = train_processed_limited[features], train_processed_limited[target].apply(lambda x: int(x * 10))\n",
        "test_idx_start = len(X) - test_size\n",
        "\n",
        "# Extract user_id before splitting\n",
        "xtrain, xtest, ytrain, ytest = X.iloc[0:test_idx_start], X.iloc[test_idx_start:], y.iloc[0:test_idx_start], y.iloc[test_idx_start:]\n",
        "\n",
        "# Function to get group sizes\n",
        "def get_group_size(df):\n",
        "    return df.groupby('user_id').size()\n",
        "\n",
        "# Get group sizes\n",
        "train_groups = get_group_size(train_processed_limited.iloc[0:test_idx_start])\n",
        "test_groups = get_group_size(train_processed_limited.iloc[test_idx_start:])\n",
        "\n",
        "print(sum(train_groups), sum(test_groups))\n",
        "# (4764372, 100000)\n",
        "\n",
        "# Train the model\n",
        "model = LGBMRanker(objective=\"lambdarank\")\n",
        "model.fit(xtrain, ytrain, group=train_groups.tolist(), eval_set=[(xtest, ytest)], eval_group=[test_groups.tolist()], eval_metric=['ndcg'])\n",
        "\n",
        "#save the model\n",
        "with open('anime_recommendation_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "import numpy as np\n",
        "user_2_anime_df = relavence_scores.groupby(\"user_id\").agg({\"anime_id\":lambda x:list(set(x))})\n",
        "user_2_anime_map = dict(zip(user_2_anime_df.index,user_2_anime_df['anime_id']))\n",
        "\n",
        "#create candidate pool, this will be a all the animes in the database\n",
        "candidate_pool = anime_info_df_final['anime_id'].unique().tolist()\n",
        "\n",
        "#anime_id to it's name mapping\n",
        "anime_id_2_name = relavence_scores.drop_duplicates(subset=[\"anime_id\",\"Name\"])[['anime_id',\"Name\"]]\n",
        "anime_id_2_name_map = dict(zip(anime_id_2_name['anime_id'],anime_id_2_name['Name']))\n",
        "\n",
        "def candidate_generation(user_id:int,candidate_pool:list,user_2_anime_map:dict,N:int):\n",
        "    \"\"\"\n",
        "    Note: this a totally random generation, only for demo purpose\n",
        "    Generates a list of N anime candidates for a given user based on their previously liked animes.\n",
        "\n",
        "    Parameters:\n",
        "        user_id (int): The user's ID.\n",
        "        candidate_pool (list): A list of all possible anime candidates.\n",
        "        user_2_anime_map (dict): A dictionary that maps users to their liked animes.\n",
        "        N (int): The number of anime candidates to generate.\n",
        "\n",
        "    Returns:\n",
        "        already_interacted (list): List of animes which user already liked\n",
        "        candidates (list): A list of N anime candidates for the user.\n",
        "    \"\"\"\n",
        "\n",
        "    #get the already liked animes\n",
        "    already_interacted = user_2_anime_map[user_id]\n",
        "\n",
        "    #candidates will be rest of animes which are not exposed to user\n",
        "    candidates = list(set(candidate_pool) - set(already_interacted))\n",
        "\n",
        "    return already_interacted,np.random.choice(candidates,size=N)\n",
        "\n",
        "def generate_predictions(user_id,user_2_anime_map,candidate_pool,feature_columns,anime_id_2_name_map,ranker,N=100):\n",
        "    \"\"\"\n",
        "    Generates predictions for anime recommendations for a given user.\n",
        "\n",
        "    Parameters:\n",
        "        user_id (int): The user's ID.\n",
        "        user_2_anime_map (dict): A dictionary that maps users to their liked animes.\n",
        "        candidate_pool (list): A list of all possible anime candidates.\n",
        "        feature_columns (list): A list of feature columns to use for generating predictions.\n",
        "        anime_id_2_name_map (dict): A dictionary that maps anime IDs to their names.\n",
        "        ranker (object): A trained model object that is used to generate predictions.\n",
        "        N (int): The number of anime predictions to generate.\n",
        "\n",
        "    Returns:\n",
        "        predictions (DataFrame): A dataframe containing the top N anime recommendations for the user.\n",
        "    \"\"\"\n",
        "    already_liked,candidates = candidate_generation(user_id,candidate_pool,user_2_anime_map,N=10000)\n",
        "\n",
        "    #Create dataframe for candidates\n",
        "    candidates_df = pd.DataFrame(data=pd.Series(candidates,name='anime_id'))\n",
        "\n",
        "    # Merge with feature dataframe\n",
        "    features = anime_info_df_final.merge(candidates_df)\n",
        "\n",
        "    #Add user id as a feature\n",
        "    features['user_id'] = user_id\n",
        "\n",
        "    # Merge with user information\n",
        "    features = features.merge(user_info)\n",
        "\n",
        "    # If number of already liked animes is less than number of candidates\n",
        "    # Extend the already liked list with -1\n",
        "    already_liked = list(already_liked)\n",
        "    if len(already_liked) < len(candidates):\n",
        "        append_list = np.full(fill_value=-1,shape=(len(candidates)-len(already_liked)))\n",
        "        already_liked.extend(list(append_list))\n",
        "\n",
        "    #Create dataframe for predictions\n",
        "    predictions = pd.DataFrame(index=candidates)\n",
        "    #Add anime names\n",
        "    predictions['name'] = np.array([anime_id_2_name_map.get(id_) for id_ in candidates])\n",
        "    #Generate predictions\n",
        "    predictions['score'] = ranker.predict(features[feature_columns])\n",
        "    predictions = predictions.sort_values(by='score',ascending=False).head(N)\n",
        "\n",
        "    predictions[f'already_liked - sample[{N}]'] = [anime_id_2_name_map.get(id_) for id_ in already_liked[0:len(predictions)]]\n",
        "    return predictions\n",
        "\n",
        "#let's generate the predictions\n",
        "generate_predictions(123,user_2_anime_map,candidate_pool,feature_columns=features,anime_id_2_name_map=anime_id_2_name_map,ranker=model,N=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "c97qStijwKgc",
        "outputId": "a7dd23ed-25c6-4836-aec4-52390032406d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-6fed26fe7ab1>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Genres'] = df['Genres'].apply(lambda x: \",\".join(s.strip() for s in x.split(\",\")))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4774372 100000\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.918345 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2389\n",
            "[LightGBM] [Info] Number of data points in the train set: 4774372, number of used features: 21\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    name     score  \\\n",
              "9002       True Tears: Raigomaru to Jibeta no Monogatari  4.327594   \n",
              "16482  Ojarumaru: Mangetsu Road Kiki Ippatsu - Tama n...  4.300468   \n",
              "3990                                       Kumo to Tulip  4.176066   \n",
              "35204                      The King of Fighters: Destiny  4.176066   \n",
              "2171   Detective Conan Movie 11: Jolly Roger in the D...  4.072907   \n",
              "30932         Oz no Mahoutsukai no Koutsuu Anzen no Tabi  4.072907   \n",
              "6272                                      Zakuro Yashiki  4.068001   \n",
              "18841            PES: Peace Eco Smile - Drive your Heart  4.062544   \n",
              "29764                                              Blend  4.062544   \n",
              "1711                              Ryuusei Sentai Musumet  3.880011   \n",
              "\n",
              "         already_liked - sample[10]  \n",
              "9002             Majo no Takkyuubin  \n",
              "16482        Tenkuu no Shiro Laputa  \n",
              "3990               Pumpkin Scissors  \n",
              "35204               Omoide Poroporo  \n",
              "2171   Heisei Tanuki Gassen Ponpoko  \n",
              "30932              Tonari no Totoro  \n",
              "6272                   Zetsuai 1989  \n",
              "18841                       Monster  \n",
              "29764                  xxxHOLiC Kei  \n",
              "1711               Shounen Onmyouji  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c9fdc7c-4f5f-4151-92a2-f7205887fdb6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>score</th>\n",
              "      <th>already_liked - sample[10]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9002</th>\n",
              "      <td>True Tears: Raigomaru to Jibeta no Monogatari</td>\n",
              "      <td>4.327594</td>\n",
              "      <td>Majo no Takkyuubin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16482</th>\n",
              "      <td>Ojarumaru: Mangetsu Road Kiki Ippatsu - Tama n...</td>\n",
              "      <td>4.300468</td>\n",
              "      <td>Tenkuu no Shiro Laputa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3990</th>\n",
              "      <td>Kumo to Tulip</td>\n",
              "      <td>4.176066</td>\n",
              "      <td>Pumpkin Scissors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35204</th>\n",
              "      <td>The King of Fighters: Destiny</td>\n",
              "      <td>4.176066</td>\n",
              "      <td>Omoide Poroporo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2171</th>\n",
              "      <td>Detective Conan Movie 11: Jolly Roger in the D...</td>\n",
              "      <td>4.072907</td>\n",
              "      <td>Heisei Tanuki Gassen Ponpoko</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30932</th>\n",
              "      <td>Oz no Mahoutsukai no Koutsuu Anzen no Tabi</td>\n",
              "      <td>4.072907</td>\n",
              "      <td>Tonari no Totoro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6272</th>\n",
              "      <td>Zakuro Yashiki</td>\n",
              "      <td>4.068001</td>\n",
              "      <td>Zetsuai 1989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18841</th>\n",
              "      <td>PES: Peace Eco Smile - Drive your Heart</td>\n",
              "      <td>4.062544</td>\n",
              "      <td>Monster</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29764</th>\n",
              "      <td>Blend</td>\n",
              "      <td>4.062544</td>\n",
              "      <td>xxxHOLiC Kei</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1711</th>\n",
              "      <td>Ryuusei Sentai Musumet</td>\n",
              "      <td>3.880011</td>\n",
              "      <td>Shounen Onmyouji</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c9fdc7c-4f5f-4151-92a2-f7205887fdb6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2c9fdc7c-4f5f-4151-92a2-f7205887fdb6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2c9fdc7c-4f5f-4151-92a2-f7205887fdb6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-40d242a9-b63b-4f61-aacb-b6eca0b0ac8a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40d242a9-b63b-4f61-aacb-b6eca0b0ac8a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-40d242a9-b63b-4f61-aacb-b6eca0b0ac8a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"generate_predictions(123,user_2_anime_map,candidate_pool,feature_columns=features,anime_id_2_name_map=anime_id_2_name_map,ranker=model,N=10)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Blend\",\n          \"Ojarumaru: Mangetsu Road Kiki Ippatsu - Tama ni wa Maro mo Daibouken\",\n          \"Oz no Mahoutsukai no Koutsuu Anzen no Tabi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13050621565987847,\n        \"min\": 3.8800114820733684,\n        \"max\": 4.32759411624847,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          4.32759411624847,\n          4.300467672170218,\n          4.062543875265853\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"already_liked - sample[10]\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"xxxHOLiC Kei\",\n          \"Tenkuu no Shiro Laputa\",\n          \"Tonari no Totoro\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "\n",
        "# Create anime_info DataFrame\n",
        "anime_info_data = {\n",
        "    'anime_id': [1, 2, 3, 4, 5],\n",
        "    'Genres': ['Action, Adventure, Comedy, Drama, Sci-Fi, Space','Action, Adventure, Comedy, Drama, Sci-Fi, Space','Action, Sci-Fi, Comedy','Action, Adventure, Drama, Fantasy, Supernatural','Action, Adventure, Drama, Fantasy, Supernatural'],\n",
        "    'is_tv': [1, 0, 1, 1, 0],\n",
        "    'year_aired': [1998, 2001, 1998, 2003, 2004],\n",
        "    'is_adult': [0] * 5,\n",
        "    'above_five_star_ratings': [800, 200, 500, 150, 50],\n",
        "    'above_five_star_ratio': [0.84, 0.78, 0.72, 0.65, 0.60]\n",
        "}\n",
        "anime_info_df = pd.DataFrame(anime_info_data)\n",
        "\n",
        "# Create relavence_scores DataFrame\n",
        "relavence_scores_data = {\n",
        "    'anime_id': [1, 2, 3, 4, 5],\n",
        "    'Name': ['Cowboy Bebop', 'Cowboy Bebop: The Movie', 'Trigun', 'Wolf\\'s Rain', 'Wolf\\'s Rain OVA'],\n",
        "    'user_id': [1, 1, 2, 2, 3],\n",
        "    'relavence_score': [0.8, 0.7, 0.9, 0.6, 0.8]\n",
        "}\n",
        "relavence_scores_df = pd.DataFrame(relavence_scores_data)\n",
        "\n",
        "# Create user_info DataFrame\n",
        "user_info_data = {\n",
        "    'user_id': [1, 2, 3],\n",
        "    'review_count': [200, 150, 100],\n",
        "    'avg_score': [8.5, 7.8, 9.2],\n",
        "    'score_stddev': [1.2, 1.5, 0.8],\n",
        "    'above_five_star_count': [150, 100, 80],\n",
        "    'above_five_star_ratio': [0.75, 0.80, 0.90]\n",
        "}\n",
        "user_info_df = pd.DataFrame(user_info_data)\n",
        "\n",
        "# Create zip file and add CSV files\n",
        "with zipfile.ZipFile('anime_dataset.zip', 'w') as zipf:\n",
        "    anime_info_df.to_csv('anime_info_new.csv', index=False)\n",
        "    relavence_scores_df.to_csv('relavence_scores_new.csv', index=False)\n",
        "    user_info_df.to_csv('user_info_new.csv', index=False)\n",
        "    zipf.write('anime_info_new.csv')\n",
        "    zipf.write('relavence_scores_new.csv')\n",
        "    zipf.write('user_info_new.csv')\n",
        "\n",
        "# Optional: Remove individual CSV files after zipping\n",
        "import os\n",
        "os.remove('anime_info_new.csv')\n",
        "os.remove('relavence_scores_new.csv')\n",
        "os.remove('user_info_new.csv')\n",
        "\n",
        "print(\"Dataset files created and zipped successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nlccyl9mGKO_",
        "outputId": "67eaea8a-3b5e-4a78-b0d5-64c9487d9f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset files created and zipped successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "\n",
        "# Step 1: Extract data from the zip file\n",
        "\n",
        "# Specify the path to your zip file\n",
        "zip_file_path = 'anime_dataset.zip'\n",
        "\n",
        "# Create a ZipFile object\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Extract all contents\n",
        "    zip_ref.extractall()\n",
        "\n",
        "# Step 2: Load data into Pandas DataFrames\n",
        "\n",
        "# Load anime_info_new.csv into a DataFrame\n",
        "anime_info_df = pd.read_csv('anime_info_new.csv')\n",
        "\n",
        "# Load relavence_scores_new.csv into a DataFrame\n",
        "relavence_scores_df = pd.read_csv('relavence_scores_new.csv')\n",
        "\n",
        "# Load user_info_new.csv into a DataFrame\n",
        "user_info_df = pd.read_csv('user_info_new.csv')\n",
        "\n",
        "# Step 3: Optionally, remove extracted CSV files\n",
        "\n",
        "# Clean up extracted CSV files\n",
        "import os\n",
        "os.remove('anime_info_new.csv')\n",
        "os.remove('relavence_scores_new.csv')\n",
        "os.remove('user_info_new.csv')\n",
        "\n",
        "# Step 4: Verify and use the loaded DataFrames\n",
        "print(\"anime_info_df:\")\n",
        "print(anime_info_df.head())\n",
        "\n",
        "print(\"\\nrelavence_scores_df:\")\n",
        "print(relavence_scores_df.head())\n",
        "\n",
        "print(\"\\nuser_info_df:\")\n",
        "print(user_info_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIJUmmLL8np9",
        "outputId": "cce6cbe7-af06-40bc-84ac-7d69a6c22619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anime_info_df:\n",
            "   anime_id                                           Genres  is_tv  \\\n",
            "0         1  Action, Adventure, Comedy, Drama, Sci-Fi, Space      1   \n",
            "1         2  Action, Adventure, Comedy, Drama, Sci-Fi, Space      0   \n",
            "2         3                           Action, Sci-Fi, Comedy      1   \n",
            "3         4  Action, Adventure, Drama, Fantasy, Supernatural      1   \n",
            "4         5  Action, Adventure, Drama, Fantasy, Supernatural      0   \n",
            "\n",
            "   year_aired  is_adult  above_five_star_ratings  above_five_star_ratio  \n",
            "0        1998         0                      800                   0.84  \n",
            "1        2001         0                      200                   0.78  \n",
            "2        1998         0                      500                   0.72  \n",
            "3        2003         0                      150                   0.65  \n",
            "4        2004         0                       50                   0.60  \n",
            "\n",
            "relavence_scores_df:\n",
            "   anime_id                     Name  user_id  relavence_score\n",
            "0         1             Cowboy Bebop        1              0.8\n",
            "1         2  Cowboy Bebop: The Movie        1              0.7\n",
            "2         3                   Trigun        2              0.9\n",
            "3         4              Wolf's Rain        2              0.6\n",
            "4         5          Wolf's Rain OVA        3              0.8\n",
            "\n",
            "user_info_df:\n",
            "   user_id  review_count  avg_score  score_stddev  above_five_star_count  \\\n",
            "0        1           200        8.5           1.2                    150   \n",
            "1        2           150        7.8           1.5                    100   \n",
            "2        3           100        9.2           0.8                     80   \n",
            "\n",
            "   above_five_star_ratio  \n",
            "0                   0.75  \n",
            "1                   0.80  \n",
            "2                   0.90  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Load the trained model\n",
        "with open('anime_recommendation_model.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# Get the feature names from the model\n",
        "model_features = model.feature_name_\n",
        "\n",
        "# Define the features we currently have\n",
        "current_features = ['anime_id', 'user_id', 'ANIME_FEATURE_IS_TV', 'ANIME_FEATURE_YEAR_AIRED',\n",
        "                    'ANIME_FEATURE_IS_ADULT', 'ANIME_FEATURE_ABOVE_FIVE_STAR_RATINGS',\n",
        "                    'ANIME_FEATURE_ABOVE_FIVE_STAR_RATIO', 'ANIME_FEATURE_COMEDY',\n",
        "                    'ANIME_FEATURE_ACTION', 'ANIME_FEATURE_FANTASY',\n",
        "                    'ANIME_FEATURE_ADVENTURE', 'ANIME_FEATURE_DRAMA', 'ANIME_FEATURE_SCI-FI',\n",
        "                    'ANIME_FEATURE_MUSIC', 'ANIME_FEATURE_SHOUNEN', 'ANIME_FEATURE_SLICE_OF_LIFE',\n",
        "                    'USER_FEATURE REVIEW_COUNT', 'USER_FEATURE AVG_SCORE',\n",
        "                    'USER_FEATURE SCORE_STDDEV', 'USER_FEATURE ABOVE_FIVE_STAR_COUNT',\n",
        "                    'USER_FEATURE ABOVE_FIVE_STAR_RATIO']\n",
        "\n",
        "# Identify missing features\n",
        "missing_features = [feature for feature in model_features if feature not in current_features]\n",
        "print(f\"Missing features: {missing_features}\")\n",
        "\n",
        "# Unzip the dataset\n",
        "zipped_data = zipfile.ZipFile(\"anime_dataset.zip\")\n",
        "\n",
        "# Load the datasets\n",
        "anime_info_df = pd.read_csv(zipped_data.open('anime_info_new.csv'))\n",
        "relavence_scores = pd.read_csv(zipped_data.open('relavence_scores_new.csv'))\n",
        "user_info = pd.read_csv(zipped_data.open('user_info_new.csv'))\n",
        "\n",
        "# Define popular genres\n",
        "popular_genres = ['Action', 'Comedy', 'Fantasy', 'Adventure', 'Drama', 'Sci-Fi', 'Music', 'Shounen', 'Slice of Life']\n",
        "\n",
        "# Function to create genre flags\n",
        "def create_genre_flags(df, popular_genres):\n",
        "    df['Genres'] = df['Genres'].fillna('')  # Replace NaN values with empty string\n",
        "    df['Genres'] = df['Genres'].str.split(', ')\n",
        "    mlb = MultiLabelBinarizer(classes=popular_genres)\n",
        "    genre_flags = mlb.fit_transform(df['Genres'])\n",
        "    genre_df = pd.DataFrame(genre_flags, columns=mlb.classes_, index=df.index)\n",
        "    new_df = pd.concat([df['anime_id'], genre_df], axis=1)\n",
        "    return new_df\n",
        "\n",
        "# Create genre flags and merge with anime info\n",
        "anime_genre_info_df = create_genre_flags(anime_info_df, popular_genres)\n",
        "anime_info_df_final = anime_info_df.merge(anime_genre_info_df, on='anime_id')\n",
        "\n",
        "# Ensure all popular genres columns are present\n",
        "for genre in popular_genres:\n",
        "    if genre not in anime_info_df_final.columns:\n",
        "        anime_info_df_final[genre] = 0\n",
        "\n",
        "# Rename columns to match the model's expected feature names\n",
        "anime_info_df_final.rename(columns={\n",
        "    'is_tv': 'ANIME_FEATURE_IS_TV',\n",
        "    'year_aired': 'ANIME_FEATURE_YEAR_AIRED',\n",
        "    'is_adult': 'ANIME_FEATURE_IS_ADULT',\n",
        "    'above_five_star_ratings': 'ANIME_FEATURE_ABOVE_FIVE_STAR_RATINGS',\n",
        "    'above_five_star_ratio': 'ANIME_FEATURE_ABOVE_FIVE_STAR_RATIO',\n",
        "    'Action': 'ANIME_FEATURE_ACTION',\n",
        "    'Comedy': 'ANIME_FEATURE_COMEDY',\n",
        "    'Fantasy': 'ANIME_FEATURE_FANTASY',\n",
        "    'Adventure': 'ANIME_FEATURE_ADVENTURE',\n",
        "    'Drama': 'ANIME_FEATURE_DRAMA',\n",
        "    'Sci-Fi': 'ANIME_FEATURE_SCI-FI',\n",
        "    'Music': 'ANIME_FEATURE_MUSIC',\n",
        "    'Shounen': 'ANIME_FEATURE_SHOUNEN',\n",
        "    'Slice of Life': 'ANIME_FEATURE_SLICE_OF_LIFE'\n",
        "}, inplace=True)\n",
        "\n",
        "# Rename user info columns\n",
        "user_info.columns = [col if col == 'user_id' else f\"USER_FEATURE {col}\".upper() for col in user_info.columns]\n",
        "\n",
        "# Merge dataframes\n",
        "test_interim = relavence_scores.merge(anime_info_df_final, on='anime_id')\n",
        "test = test_interim.merge(user_info, on='user_id', how='inner')\n",
        "\n",
        "# Define the function to limit entries per user (if needed)\n",
        "def limit_entries_per_user(df, limit=8000):\n",
        "    return df.groupby('user_id').apply(lambda x: x.head(limit)).reset_index(drop=True)\n",
        "\n",
        "# Limit entries per user (if needed)\n",
        "test_limited = limit_entries_per_user(test)\n",
        "\n",
        "# Sort by user_id (if needed)\n",
        "test_limited.sort_values(by='user_id', inplace=True)\n",
        "\n",
        "# Define features (ensure consistency with the training data)\n",
        "features = ['anime_id', 'user_id', 'ANIME_FEATURE_IS_TV',\n",
        "       'ANIME_FEATURE_YEAR_AIRED', 'ANIME_FEATURE_IS_ADULT',\n",
        "       'ANIME_FEATURE_ABOVE_FIVE_STAR_RATINGS',\n",
        "       'ANIME_FEATURE_ABOVE_FIVE_STAR_RATIO', 'ANIME_FEATURE_COMEDY',\n",
        "       'ANIME_FEATURE_ACTION', 'ANIME_FEATURE_FANTASY',\n",
        "       'ANIME_FEATURE_ADVENTURE', 'ANIME_FEATURE_DRAMA', 'ANIME_FEATURE_SCI-FI',\n",
        "       'ANIME_FEATURE_MUSIC', 'ANIME_FEATURE_SHOUNEN',\n",
        "       'ANIME_FEATURE_SLICE_OF_LIFE', 'USER_FEATURE REVIEW_COUNT',\n",
        "       'USER_FEATURE AVG_SCORE', 'USER_FEATURE SCORE_STDDEV',\n",
        "       'USER_FEATURE ABOVE_FIVE_STAR_COUNT',\n",
        "       'USER_FEATURE ABOVE_FIVE_STAR_RATIO']\n",
        "\n",
        "# Ensure all necessary columns are present in test_limited\n",
        "for col in missing_features:\n",
        "    test_limited[col] = 0  # or np.nan, depending on the data type and model requirements\n",
        "\n",
        "# Ensure all features are present in the correct order\n",
        "all_features = features + missing_features\n",
        "test_limited = test_limited[all_features]\n",
        "\n",
        "# Define the candidate_generation function\n",
        "def candidate_generation(user_id, candidate_pool, user_2_anime_map, N=8000):\n",
        "    already_liked = set(user_2_anime_map.get(user_id, []))\n",
        "    candidates = list(set(candidate_pool) - already_liked)\n",
        "    return already_liked, candidates[:N]\n",
        "# Define anime_id_2_name_map\n",
        "anime_id_2_name_map = {row['anime_id']: row['Name'] for _, row in anime_info_df.iterrows()}\n",
        "\n",
        "# Define the generate_predictions function as before\n",
        "def generate_predictions(user_id, user_2_anime_map, candidate_pool, feature_columns, anime_id_2_name_map, ranker, N=10):\n",
        "    already_liked, candidates = candidate_generation(user_id, candidate_pool, user_2_anime_map, N=10000)\n",
        "\n",
        "    # Create dataframe for candidates\n",
        "    candidates_df = pd.DataFrame(data=pd.Series(candidates, name='anime_id'))\n",
        "\n",
        "    # Merge with feature dataframe\n",
        "    features = anime_info_df_final.merge(candidates_df, on='anime_id')\n",
        "\n",
        "    # Add user id as a feature\n",
        "    features['user_id'] = user_id\n",
        "\n",
        "    # Merge with user information\n",
        "    features = features.merge(user_info, on='user_id')\n",
        "\n",
        "    # If number of already liked animes is less than number of candidates\n",
        "    # Extend the already liked list with -1\n",
        "    already_liked = list(already_liked)\n",
        "    if len(already_liked) < len(candidates):\n",
        "        append_list = np.full(fill_value=-1, shape=(len(candidates) - len(already_liked)))\n",
        "        already_liked.extend(list(append_list))\n",
        "\n",
        "    # Create dataframe for predictions\n",
        "    predictions = pd.DataFrame(index=candidates)\n",
        "    # Add anime names\n",
        "    predictions['name'] = [anime_id_2_name_map.get(id_) for id_ in candidates]\n",
        "    # Generate predictions\n",
        "    predictions['score'] = ranker.predict(features[feature_columns])\n",
        "    predictions = predictions.sort_values(by='score', ascending=False).head(N)\n",
        "\n",
        "    predictions[f'already_liked - sample[{N}]'] = [anime_id_2_name_map.get(id_) for id_ in already_liked[0:len(predictions)]]\n",
        "    return predictions\n",
        "\n",
        "# Define user_id, user_2_anime_map, and candidate_pool\n",
        "user_id = 1  # Example user_id\n",
        "user_2_anime_map = {}  # Provide the actual mapping (e.g., {1: [10, 20, 30]})\n",
        "candidate_pool = anime_info_df_final['anime_id'].tolist()  # Example candidate pool\n",
        "\n",
        "# Generate predictions\n",
        "predictions = generate_predictions(user_id, user_2_anime_map, candidate_pool, features, anime_id_2_name_map, model, N=10)\n",
        "\n",
        "# Display the top recommendations\n",
        "print(predictions)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "48xkYII5GQnI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "cf9fea25-e60e-4801-fe17-2bcf39119133",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing features: ['USER_FEATURE_REVIEW_COUNT', 'USER_FEATURE_AVG_SCORE', 'USER_FEATURE_SCORE_STDDEV', 'USER_FEATURE_ABOVE_FIVE_STAR_COUNT', 'USER_FEATURE_ABOVE_FIVE_STAR_RATIO']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['Space', 'Supernatural'] will be ignored\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Name'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Name'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-65185cbede9e>\u001b[0m in \u001b[0;36m<cell line: 121>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0malready_liked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m# Define anime_id_2_name_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0manime_id_2_name_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'anime_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manime_info_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m# Define the generate_predictions function as before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-65185cbede9e>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0malready_liked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m# Define anime_id_2_name_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0manime_id_2_name_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'anime_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manime_info_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m# Define the generate_predictions function as before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Name'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "\n",
        "# Load the datasets from the zip file\n",
        "with zipfile.ZipFile(\"anime_dataset.zip\", \"r\") as z:\n",
        "    with z.open('anime_info_new.csv') as f1, z.open('relavence_scores_new.csv') as f2, z.open('user_info_new.csv') as f3:\n",
        "        anime_info_df = pd.read_csv(f1)\n",
        "        relavence_scores_df = pd.read_csv(f2)\n",
        "        user_info_df = pd.read_csv(f3)\n",
        "\n",
        "# Verify column names in relavence_scores_df\n",
        "print(\"Column names in relavence_scores_df:\", relavence_scores_df.columns)\n",
        "\n",
        "# Define anime_id_2_name_map using the 'Name' column from relavence_scores_df\n",
        "anime_id_2_name_map = {row['anime_id']: row['Name'] for _, row in relavence_scores_df.iterrows()}\n",
        "\n",
        "# Print the anime_id_2_name_map to verify\n",
        "print(anime_id_2_name_map)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6j9Mtj_-3UI",
        "outputId": "e2d4ec89-3e7e-458e-9883-5806cf632d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names in relavence_scores_df: Index(['anime_id', 'Name', 'user_id', 'relavence_score'], dtype='object')\n",
            "{1: 'Cowboy Bebop', 2: 'Cowboy Bebop: The Movie', 3: 'Trigun', 4: \"Wolf's Rain\", 5: \"Wolf's Rain OVA\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import pickle\n",
        "\n",
        "# Unzip the dataset\n",
        "zipped_data = zipfile.ZipFile(\"anime_dataset.zip\")\n",
        "\n",
        "# Load the datasets\n",
        "anime_info_df = pd.read_csv(zipped_data.open('anime_info_new.csv'))\n",
        "relavence_scores = pd.read_csv(zipped_data.open('relavence_scores_new.csv'))\n",
        "user_info = pd.read_csv(zipped_data.open('user_info_new.csv'))\n",
        "\n",
        "# Define popular genres\n",
        "popular_genres = ['Action', 'Comedy', 'Fantasy', 'Adventure', 'Drama', 'Sci-Fi', 'Music', 'Shounen', 'Slice of Life']\n",
        "\n",
        "# Function to create genre flags\n",
        "def create_genre_flags(df, popular_genres):\n",
        "    df['Genres'] = df['Genres'].fillna('')  # Replace NaN values with empty string\n",
        "    df['Genres'] = df['Genres'].str.split(', ')\n",
        "    mlb = MultiLabelBinarizer(classes=popular_genres)\n",
        "    genre_flags = mlb.fit_transform(df['Genres'])\n",
        "    genre_df = pd.DataFrame(genre_flags, columns=mlb.classes_, index=df.index)\n",
        "    new_df = pd.concat([df['anime_id'], genre_df], axis=1)\n",
        "    return new_df\n",
        "\n",
        "# Create genre flags and merge with anime info\n",
        "anime_genre_info_df = create_genre_flags(anime_info_df, popular_genres)\n",
        "anime_info_df_final = anime_info_df.merge(anime_genre_info_df, on='anime_id')\n",
        "\n",
        "# Ensure all popular genres columns are present\n",
        "for genre in popular_genres:\n",
        "    if genre not in anime_info_df_final.columns:\n",
        "        anime_info_df_final[genre] = 0\n",
        "\n",
        "print(anime_info_df_final.head())  # Check the merged dataframe to see if genre columns are present\n",
        "\n",
        "# Rename user info columns\n",
        "user_info.columns = [col if col == 'user_id' else f\"USER_FEATURE {col}\".upper() for col in user_info.columns]\n",
        "\n",
        "# Merge dataframes\n",
        "test_interim = relavence_scores.merge(anime_info_df_final, on='anime_id')\n",
        "test = test_interim.merge(user_info, on='user_id', how='inner')\n",
        "\n",
        "# Define the function to limit entries per user (if needed)\n",
        "def limit_entries_per_user(df, limit=10000):\n",
        "    return df.groupby('user_id').apply(lambda x: x.head(limit)).reset_index(drop=True)\n",
        "\n",
        "# Limit entries per user (if needed)\n",
        "test_limited = limit_entries_per_user(test)\n",
        "\n",
        "# Sort by user_id (if needed)\n",
        "test_limited.sort_values(by='user_id', inplace=True)\n",
        "\n",
        "# Define features (ensure consistency with the training data)\n",
        "features = ['anime_id', 'user_id', 'is_tv',\n",
        "       'year_aired', 'is_adult',\n",
        "       'above_five_star_ratings',\n",
        "       'above_five_star_ratio', 'Comedy',\n",
        "       'Action', 'Fantasy',\n",
        "       'Adventure', 'Drama', 'Sci-Fi',\n",
        "       'Music', 'Shounen',\n",
        "       'Slice of Life', 'USER_FEATURE REVIEW_COUNT',\n",
        "       'USER_FEATURE AVG_SCORE', 'USER_FEATURE SCORE_STDDEV',\n",
        "       'USER_FEATURE ABOVE_FIVE_STAR_COUNT',\n",
        "       'USER_FEATURE ABOVE_FIVE_STAR_RATIO']\n",
        "\n",
        "# Ensure all necessary columns are present in test_limited\n",
        "missing_columns = [col for col in features if col not in test_limited.columns]\n",
        "for col in missing_columns:\n",
        "    test_limited[col] = 0  # or np.nan, depending on the data type and model requirements\n",
        "\n",
        "# Filter to only the necessary columns\n",
        "test_limited = test_limited[features]\n",
        "\n",
        "# Load the trained model\n",
        "with open('anime_recommendation_model.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# Generate predictions for a specific user\n",
        "user_id = 2  # Change this to the user_id you want recommendations for\n",
        "\n",
        "# Define the function to generate predictions (assuming it is already defined)\n",
        "# Make sure the function is adjusted to take these inputs correctly\n",
        "def generate_predictions(user_id, user_2_anime_map, candidate_pool, feature_columns, anime_id_2_name_map, ranker, N=10):\n",
        "    \"\"\"\n",
        "    Generates predictions for anime recommendations for a given user.\n",
        "\n",
        "    Parameters:\n",
        "        user_id (int): The user's ID.\n",
        "        user_2_anime_map (dict): A dictionary that maps users to their liked animes.\n",
        "        candidate_pool (list): A list of all possible anime candidates.\n",
        "        feature_columns (list): A list of feature columns to use for generating predictions.\n",
        "        anime_id_2_name_map (dict): A dictionary that maps anime IDs to their names.\n",
        "        ranker (object): A trained model object that is used to generate predictions.\n",
        "        N (int): The number of anime predictions to generate.\n",
        "\n",
        "    Returns:\n",
        "        predictions (DataFrame): A dataframe containing the top N anime recommendations for the user.\n",
        "    \"\"\"\n",
        "    already_liked, candidates = candidate_generation(user_id, candidate_pool, user_2_anime_map, N=10000)\n",
        "\n",
        "    # Create dataframe for candidates\n",
        "    candidates_df = pd.DataFrame(data=pd.Series(candidates, name='anime_id'))\n",
        "\n",
        "    # Merge with feature dataframe\n",
        "    features = anime_info_df_final.merge(candidates_df, on='anime_id')\n",
        "\n",
        "    # Add user id as a feature\n",
        "    features['user_id'] = user_id\n",
        "\n",
        "    # Merge with user information\n",
        "    features = features.merge(user_info, on='user_id')\n",
        "\n",
        "    # If number of already liked animes is less than number of candidates\n",
        "    # Extend the already liked list with -1\n",
        "    already_liked = list(already_liked)\n",
        "    if len(already_liked) < len(candidates):\n",
        "        append_list = np.full(fill_value=-1, shape=(len(candidates) - len(already_liked)))\n",
        "        already_liked.extend(list(append_list))\n",
        "\n",
        "    # Create dataframe for predictions\n",
        "    predictions = pd.DataFrame(index=candidates)\n",
        "    # Add anime names\n",
        "    predictions['name'] = [anime_id_2_name_map.get(id_) for id_ in candidates]\n",
        "    # Generate predictions\n",
        "    predictions['score'] = ranker.predict(features[feature_columns])\n",
        "    predictions = predictions.sort_values(by='score', ascending=False).head(N)\n",
        "\n",
        "    predictions[f'already_liked - sample[{N}]'] = [anime_id_2_name_map.get(id_) for id_ in already_liked[0:len(predictions)]]\n",
        "    return predictions\n",
        "\n",
        "# Candidate generation function\n",
        "def candidate_generation(user_id, candidate_pool, user_2_anime_map, N=100):\n",
        "    \"\"\"\n",
        "    Generates a list of N anime candidates for a given user based on their previously liked animes.\n",
        "\n",
        "    Parameters:\n",
        "        user_id (int): The user's ID.\n",
        "        candidate_pool (list): A list of all possible anime candidates.\n",
        "        user_2_anime_map (dict): A dictionary that maps users to their liked animes.\n",
        "        N (int): The number of anime candidates to generate.\n",
        "\n",
        "    Returns:\n",
        "        already_interacted (list): List of animes which user already liked.\n",
        "        candidates (list): A list of N anime candidates for the user.\n",
        "    \"\"\"\n",
        "    # Get the already liked animes\n",
        "    already_interacted = user_2_anime_map.get(user_id, [])\n",
        "\n",
        "    # Candidates will be the rest of animes which are not exposed to user\n",
        "    candidates = list(set(candidate_pool) - set(already_interacted))\n",
        "\n",
        "    return already_interacted, np.random.choice(candidates, size=N)\n",
        "\n",
        "# Create candidate pool and mappings\n",
        "candidate_pool = anime_info_df_final['anime_id'].unique().tolist()\n",
        "anime_id_2_name = relavence_scores.drop_duplicates(subset=[\"anime_id\", \"Name\"])[['anime_id', \"Name\"]]\n",
        "anime_id_2_name_map = dict(zip(anime_id_2_name['anime_id'], anime_id_2_name['Name']))\n",
        "\n",
        "# Create user to anime map\n",
        "user_2_anime_df = relavence_scores.groupby(\"user_id\").agg({\"anime_id\": lambda x: list(set(x))})\n",
        "user_2_anime_map = dict(zip(user_2_anime_df.index, user_2_anime_df['anime_id']))\n",
        "\n",
        "# Generate predictions\n",
        "predictions = generate_predictions(user_id, user_2_anime_map, candidate_pool, features, anime_id_2_name_map, model, N=10)\n",
        "\n",
        "# Display the top recommendations\n",
        "print(predictions)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHsemEPPBbkl",
        "outputId": "17a42add-ac4b-47ef-da3b-d8b658e6c1aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) ['Space', 'Supernatural'] will be ignored\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   anime_id                                             Genres  is_tv  \\\n",
            "0         1  [Action, Adventure, Comedy, Drama, Sci-Fi, Space]      1   \n",
            "1         2  [Action, Adventure, Comedy, Drama, Sci-Fi, Space]      0   \n",
            "2         3                           [Action, Sci-Fi, Comedy]      1   \n",
            "3         4  [Action, Adventure, Drama, Fantasy, Supernatural]      1   \n",
            "4         5  [Action, Adventure, Drama, Fantasy, Supernatural]      0   \n",
            "\n",
            "   year_aired  is_adult  above_five_star_ratings  above_five_star_ratio  \\\n",
            "0        1998         0                      800                   0.84   \n",
            "1        2001         0                      200                   0.78   \n",
            "2        1998         0                      500                   0.72   \n",
            "3        2003         0                      150                   0.65   \n",
            "4        2004         0                       50                   0.60   \n",
            "\n",
            "   Action  Comedy  Fantasy  Adventure  Drama  Sci-Fi  Music  Shounen  \\\n",
            "0       1       1        0          1      1       1      0        0   \n",
            "1       1       1        0          1      1       1      0        0   \n",
            "2       1       1        0          0      0       1      0        0   \n",
            "3       1       0        1          1      1       0      0        0   \n",
            "4       1       0        1          1      1       0      0        0   \n",
            "\n",
            "   Slice of Life  \n",
            "0              0  \n",
            "1              0  \n",
            "2              0  \n",
            "3              0  \n",
            "4              0  \n",
            "                      name     score already_liked - sample[10]\n",
            "2  Cowboy Bebop: The Movie  3.934259                     Trigun\n",
            "2  Cowboy Bebop: The Movie  3.934259                Wolf's Rain\n",
            "1             Cowboy Bebop  3.934259                       None\n",
            "5          Wolf's Rain OVA  3.934259                       None\n",
            "5          Wolf's Rain OVA  3.934259                       None\n",
            "2  Cowboy Bebop: The Movie  3.934259                       None\n",
            "1             Cowboy Bebop  3.934259                       None\n",
            "2  Cowboy Bebop: The Movie  3.934259                       None\n",
            "5          Wolf's Rain OVA  3.934259                       None\n",
            "2  Cowboy Bebop: The Movie  3.934259                       None\n"
          ]
        }
      ]
    }
  ]
}